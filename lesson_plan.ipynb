{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db3674f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM (Groq) ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.\n",
      "‚úÖ Kho tri th·ª©c RAG ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 1: C√ÄI ƒê·∫∂T, IMPORTS & THI·∫æT L·∫¨P BAN ƒê·∫¶U\n",
    "# ==============================================================================\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import operator\n",
    "from typing import TypedDict, Annotated, List, Dict, Any, Literal, Optional, Union\n",
    "\n",
    "# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "# LangChain & LangGraph\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Th∆∞ vi·ªán h·ªó tr·ª£ & Kho tri th·ª©c\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.pretty import pprint\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- C·∫§U H√åNH LOG ---\n",
    "VERBOSE_MODE = True\n",
    "\n",
    "# --- KH·ªûI T·∫†O C√ÅC C√îNG C·ª§ IN ·∫§N ---\n",
    "console = Console()\n",
    "\n",
    "def print_step(message: str):\n",
    "    if VERBOSE_MODE:\n",
    "        console.print(f\"\\n[bold cyan]>[/bold cyan] {message}\")\n",
    "\n",
    "def print_result(data: Any, title: str = \"K·∫øt qu·∫£\"):\n",
    "    if VERBOSE_MODE:\n",
    "        console.print(f\"[bold green]‚úîÔ∏è {title}:[/bold green]\")\n",
    "        pprint(data, expand_all=True)\n",
    "        \n",
    "def print_warning(message: str):\n",
    "    if VERBOSE_MODE:\n",
    "        console.print(f\"[bold yellow]‚ö†Ô∏è  {message}[/bold yellow]\")\n",
    "\n",
    "# --- KH·ªûI T·∫†O LLM ---\n",
    "try:\n",
    "    llm = ChatGroq(\n",
    "        temperature=0.1, model=\"llama3-70b-8192\",\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\"), max_tokens=4096,\n",
    "        max_retries=2\n",
    "    )\n",
    "    print(\"‚úÖ LLM (Groq) ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªñI: Kh√¥ng th·ªÉ kh·ªüi t·∫°o LLM. L·ªói: {e}\")\n",
    "    llm = None\n",
    "\n",
    "# --- T·∫¢I KHO TRI TH·ª®C ---\n",
    "VECTOR_STORE_PATH = \"vector_store/sgk_toan_9\"\n",
    "vector_store = None\n",
    "if os.path.exists(VECTOR_STORE_PATH):\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        vector_store = FAISS.load_local(VECTOR_STORE_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "        print(\"‚úÖ Kho tri th·ª©c RAG ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªñI khi t·∫£i kho tri th·ª©c: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y kho tri th·ª©c t·∫°i '{VECTOR_STORE_PATH}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16495681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ C·∫•u tr√∫c State 'TeacherStateV4' ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.\n",
      "‚úÖ T·∫•t c·∫£ c√°c Pydantic Models ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: KI·∫æN TR√öC D·ªÆ LI·ªÜU (STATE & PYDANTIC MODELS)\n",
    "# ==============================================================================\n",
    "from typing import TypedDict, Annotated, List, Dict, Any, Literal, Optional\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# --- ƒê·ªäNH NGHƒ®A STATE ---\n",
    "def merge_dicts(dict1: Dict[str, Any], dict2: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    merged = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):\n",
    "            merged[key] = merge_dicts(merged[key], value)\n",
    "        else:\n",
    "            merged[key] = value\n",
    "    return merged\n",
    "\n",
    "class DetailedTask(TypedDict):\n",
    "    task_id: int\n",
    "    task_name: str\n",
    "    task_description: str\n",
    "    estimated_duration: int \n",
    "    status: Literal[\"pending\", \"completed\"]\n",
    "\n",
    "class TeacherStateV4(TypedDict):\n",
    "    original_request: str\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    analyzed_objective: Optional[Any]\n",
    "    pedagogy_strategy: Optional[Any]\n",
    "    expanded_queries: Optional[List[str]]\n",
    "    task_list: Optional[List[DetailedTask]]\n",
    "    current_task_id: Optional[int]\n",
    "    reflection_notes: Optional[str]\n",
    "    agent_outputs: Annotated[Dict[str, Any], merge_dicts] \n",
    "    final_lesson_plan: Optional[str]\n",
    "    next_agent: str\n",
    "    \n",
    "    # C√°c tr∆∞·ªùng m·ªõi cho phi√™n b·∫£n t·ª± s·ª≠a l·ªói\n",
    "    current_content_to_validate: Optional[Dict[str, Any]]\n",
    "    validation_feedback: Optional[str]\n",
    "    domain: Optional[str]\n",
    "    student_persona: Optional[Dict[str, Any]]\n",
    "    pedagogical_blueprint: Optional[List[str]]\n",
    "\n",
    "\n",
    "print(\"‚úÖ C·∫•u tr√∫c State 'TeacherStateV4' ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.\")\n",
    "\n",
    "# --- ƒê·ªäNH NGHƒ®A C√ÅC PYDANTIC MODELS ---\n",
    "class LearningActivity(BaseModel):\n",
    "    activity_name: str = Field(description=\"T√™n c·ªßa ho·∫°t ƒë·ªông h·ªçc t·∫≠p n√†y th·∫≠t h·∫•p d·∫´n v√† r√µ r√†ng.\")\n",
    "    description: str = Field(description=\"M√¥ t·∫£ chi ti·∫øt c√°c b∆∞·ªõc gi√°o vi√™n v√† h·ªçc sinh c·∫ßn th·ª±c hi·ªán trong ho·∫°t ƒë·ªông.\")\n",
    "    duration_minutes: int = Field(description=\"Th·ªùi gian ∆∞·ªõc t√≠nh (b·∫±ng S·ªê PH√öT) ƒë·ªÉ ho√†n th√†nh ho·∫°t ƒë·ªông.\")\n",
    "    activity_type: str = Field(description=\"Ph√¢n lo·∫°i ho·∫°t ƒë·ªông (v√≠ d·ª•: 'Gi·∫£ng gi·∫£i l√Ω thuy·∫øt', 'Luy·ªán t·∫≠p c·∫∑p ƒë√¥i', 'Th·∫£o lu·∫≠n nh√≥m', 'Tr√≤ ch∆°i').\")\n",
    "    solution_guide: Optional[Any] = Field(description=\"H∆∞·ªõng d·∫´n gi·∫£i, ƒë√°p √°n chi ti·∫øt ho·∫∑c c√°c ƒëi·ªÉm ch√≠nh c·∫ßn l∆∞u √Ω.\")\n",
    "\n",
    "class AssessmentItem(BaseModel):\n",
    "    question: str = Field(description=\"N·ªôi dung c√¢u h·ªèi ho·∫∑c ƒë·ªÅ b√†i to√°n, ƒë∆∞·ª£c vi·∫øt r√µ r√†ng, d·ªÖ hi·ªÉu.\")\n",
    "    question_type: str = Field(description=\"Lo·∫°i c√¢u h·ªèi (v√≠ d·ª•: 'Tr·∫Øc nghi·ªám', 'T·ª± lu·∫≠n', 'Ch·ª©ng minh').\")\n",
    "    options: Optional[List[str]] = Field(description=\"C√°c l·ª±a ch·ªçn n·∫øu l√† c√¢u h·ªèi tr·∫Øc nghi·ªám.\")\n",
    "    answer: str = Field(description=\"ƒê√°p √°n ch√≠nh x√°c v√† ng·∫Øn g·ªçn cho c√¢u h·ªèi.\")\n",
    "    solution_guide: Any = Field(description=\"H∆∞·ªõng d·∫´n gi·∫£i chi ti·∫øt t·ª´ng b∆∞·ªõc ƒë·ªÉ h·ªçc sinh c√≥ th·ªÉ t·ª± ki·ªÉm tra.\")\n",
    "\n",
    "class DetailedTaskModel(BaseModel):\n",
    "    task_name: str = Field(description=\"T√™n c·ªßa nhi·ªám v·ª• n√†y.\")\n",
    "    task_description: str = Field(description=\"M√¥ t·∫£ chi ti·∫øt nhi·ªám v·ª• c·∫ßn th·ª±c hi·ªán.\")\n",
    "    estimated_duration: int = Field(description=\"Th·ªùi gian ∆∞·ªõc t√≠nh (b·∫±ng ph√∫t) cho nhi·ªám v·ª• n√†y.\")\n",
    "\n",
    "class TaskListWithDuration(BaseModel):\n",
    "    tasks: List[DetailedTaskModel]\n",
    "\n",
    "class ParsedObjective(BaseModel):\n",
    "    action_verb: str\n",
    "    bloom_level: int\n",
    "    topic: str\n",
    "    grade_level: str\n",
    "    duration_minutes: Optional[int]\n",
    "\n",
    "class PedagogyChoice(BaseModel):\n",
    "    chosen_pedagogy: str\n",
    "    pedagogy_rationale: str\n",
    "\n",
    "class ExpandedQueries(BaseModel):\n",
    "    queries: List[str]\n",
    "\n",
    "class BestSnippets(BaseModel):\n",
    "    best_snippets: List[str]\n",
    "\n",
    "class TaskClassification(BaseModel):\n",
    "    agent_category: Literal[\"activity_designer\", \"theory_synthesizer\", \"assessment_creator\"]\n",
    "    \n",
    "class ValidationResult(BaseModel):\n",
    "    is_valid: bool\n",
    "    feedback: str\n",
    "    \n",
    "class Domain(BaseModel):\n",
    "    domain: str\n",
    "    \n",
    "class StudentPersona(BaseModel):\n",
    "    learning_pace: Literal[\"nhanh\", \"trung b√¨nh\", \"ch·∫≠m\"]\n",
    "    engagement_style: Literal[\"ch·ªß ƒë·ªông\", \"th·ª• ƒë·ªông\", \"h·ªón h·ª£p\"]\n",
    "    special_notes: str\n",
    "    \n",
    "class PedagogicalBlueprint(BaseModel):\n",
    "    blueprint: List[str]\n",
    "\n",
    "print(\"‚úÖ T·∫•t c·∫£ c√°c Pydantic Models ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e71503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 3: AGENTS - GIAI ƒêO·∫†N PH√ÇN T√çCH & L·∫¨P CHI·∫æN L∆Ø·ª¢C\n",
    "# ==============================================================================\n",
    "\n",
    "SYSTEM_PERSONA_PROMPT = \"B·∫†N L√Ä M·ªòT TR·ª¢ L√ù AI CHUY√äN NGHI·ªÜP, ƒê√ìNG VAI TR√í M·ªòT GI√ÅO VI√äN GI√ÄU KINH NGHI·ªÜM T·∫†I VI·ªÜT NAM. LU√îN LU√îN tr·∫£ l·ªùi b·∫±ng TI·∫æNG VI·ªÜT.\"\n",
    "\n",
    "async def objective_interpreter_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Objective Interpreter` ƒëang ph√¢n t√≠ch m·ª•c ti√™u...\")\n",
    "    prompt = f\"{SYSTEM_PERSONA_PROMPT}\\n**NHI·ªÜM V·ª§:** ƒê·ªçc y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng v√† tr√≠ch xu·∫•t c√°c th√¥ng tin sau.\\n**Y√äU C·∫¶U:** \\\"{state['original_request']}\\\"\\n**C√ÅC TR∆Ø·ªúNG C·∫¶N TR√çCH XU·∫§T:** `action_verb`, `bloom_level` (S·ªê NGUY√äN), `topic`, `grade_level`, `duration_minutes`.\\n**CH·ªà TR·∫¢ V·ªÄ JSON.**\"\n",
    "    structured_llm = llm.with_structured_output(ParsedObjective, method=\"json_mode\")\n",
    "    try:\n",
    "        parsed_result = await structured_llm.ainvoke(prompt)\n",
    "        analyzed_objective_dict = parsed_result.dict()\n",
    "        analyzed_objective_dict['constraints'] = {'duration_minutes': parsed_result.duration_minutes}\n",
    "        del analyzed_objective_dict['duration_minutes']\n",
    "        print_result(analyzed_objective_dict, \"M·ª•c ti√™u & R√†ng bu·ªôc ƒë√£ ph√¢n t√≠ch\")\n",
    "        return {\"analyzed_objective\": analyzed_objective_dict}\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Objective Interpreter: {e}. S·ª≠ d·ª•ng m·ª•c ti√™u m·∫∑c ƒë·ªãnh.\")\n",
    "        return {\"analyzed_objective\": { \"action_verb\": \"so·∫°n\", \"bloom_level\": 3, \"topic\": state['original_request'], \"grade_level\": \"9\", \"constraints\": {\"duration_minutes\": 90} }}\n",
    "\n",
    "async def pedagogy_strategist_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Pedagogy Strategist` ƒëang ch·ªçn ph∆∞∆°ng ph√°p s∆∞ ph·∫°m...\")\n",
    "    prompt = f\"{SYSTEM_PERSONA_PROMPT}\\n**NHI·ªÜM V·ª§:** D·ª±a tr√™n m·ª•c ti√™u b√†i h·ªçc, ch·ªçn M·ªòT ph∆∞∆°ng ph√°p s∆∞ ph·∫°m v√† gi·∫£i th√≠ch ng·∫Øn g·ªçn.\\n**M·ª§C TI√äU:** {state.get('analyzed_objective')}\\n**Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:** Tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON v·ªõi 2 keys: `chosen_pedagogy` v√† `pedagogy_rationale`.\"\n",
    "    structured_llm = llm.with_structured_output(PedagogyChoice, method=\"json_mode\")\n",
    "    try:\n",
    "        response = await structured_llm.ainvoke(prompt)\n",
    "        print_result(response.dict(), \"Chi·∫øn l∆∞·ª£c s∆∞ ph·∫°m ƒë√£ ch·ªçn\")\n",
    "        return {\"pedagogy_strategy\": response.dict()}\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Pedagogy Strategist: {e}. S·ª≠ d·ª•ng chi·∫øn l∆∞·ª£c m·∫∑c ƒë·ªãnh.\")\n",
    "        return {\"pedagogy_strategy\": {\"chosen_pedagogy\": \"D·∫°y h·ªçc gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ\", \"pedagogy_rationale\": \"M·∫∑c ƒë·ªãnh do l·ªói.\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "645cff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 4: AGENTS - GIAI ƒêO·∫†N THU TH·∫¨P & L·∫¨P K·∫æ HO·∫†CH CHI TI·∫æT\n",
    "# ==============================================================================\n",
    "\n",
    "def update_agent_outputs(state: \"TeacherStateV4\", key: str, value: Any) -> Dict[str, Any]:\n",
    "    outputs = state.get(\"agent_outputs\", {}).copy()\n",
    "    if key not in outputs: outputs[key] = []\n",
    "    outputs[key].append(value)\n",
    "    return {\"agent_outputs\": outputs}\n",
    "\n",
    "async def query_expansion_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Query Expansion` ƒëang m·ªü r·ªông truy v·∫•n t√¨m ki·∫øm...\")\n",
    "    objective = state.get('analyzed_objective', {})\n",
    "    prompt = f\"{SYSTEM_PERSONA_PROMPT}\\n**NHI·ªÜM V·ª§:** T·∫°o ra c√°c c·ª•m t·ª´ t√¨m ki·∫øm ƒëa d·∫°ng b·∫±ng ti·∫øng Vi·ªát ƒë·ªÉ t√¨m t√†i li·ªáu.\\n**CH·ª¶ ƒê·ªÄ:** \\\"{objective.get('topic', '')}\\\"\\n**Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:** Tr·∫£ v·ªÅ JSON v·ªõi key `queries`.\"\n",
    "    structured_llm = llm.with_structured_output(ExpandedQueries, method=\"json_mode\")\n",
    "    try:\n",
    "        response = await structured_llm.ainvoke(prompt)\n",
    "        print_result(response.queries, \"C√°c truy v·∫•n t√¨m ki·∫øm ƒë√£ ƒë∆∞·ª£c m·ªü r·ªông\")\n",
    "        return {\"expanded_queries\": response.queries}\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Query Expansion: {e}. S·ª≠ d·ª•ng truy v·∫•n g·ªëc.\")\n",
    "        return {\"expanded_queries\": [objective.get('topic', '')]}\n",
    "\n",
    "async def resource_scout_agent_v2(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Resource Scout` ƒëang t√¨m ki·∫øm v√† s√†ng l·ªçc t√†i li·ªáu...\")\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "    all_docs = []\n",
    "    queries = state.get('expanded_queries', [])\n",
    "    for query in queries:\n",
    "        all_docs.extend(retriever.invoke(query))\n",
    "    unique_docs_content = list({doc.page_content for doc in all_docs})[:8]\n",
    "    print_step(f\"T√¨m th·∫•y {len(all_docs)} t√†i li·ªáu, s√†ng l·ªçc c√≤n {len(unique_docs_content)} ƒëo·∫°n vƒÉn b·∫£n ƒë·ªôc nh·∫•t.\")\n",
    "    \n",
    "    rerank_prompt = f\"{SYSTEM_PERSONA_PROMPT}\\n**NHI·ªÜM V·ª§:** ƒê·ªçc y√™u c·∫ßu g·ªëc v√† ch·ªçn ra 3-4 ƒëo·∫°n vƒÉn b·∫£n ti·∫øng Vi·ªát ph√π h·ª£p NH·∫§T t·ª´ danh s√°ch d∆∞·ªõi ƒë√¢y.\\n**Y√äU C·∫¶U G·ªêC:** \\\"{state.get('original_request', '')}\\\"\\n**DANH S√ÅCH T√ÄI LI·ªÜU:** {json.dumps(unique_docs_content, ensure_ascii=False)}\\n**Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:** Tr·∫£ v·ªÅ JSON v·ªõi key `best_snippets`.\"\n",
    "    structured_llm_reranker = llm.with_structured_output(BestSnippets, method=\"json_mode\")\n",
    "    best_snippets_text = \"\\n\\n---\\n\\n\".join(unique_docs_content)\n",
    "    try:\n",
    "        reranked_result = await structured_llm_reranker.ainvoke(rerank_prompt)\n",
    "        best_snippets_text = \"\\n\\n---\\n\\n\".join(reranked_result.best_snippets)\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Re-ranker: {e}. S·ª≠ d·ª•ng t·∫•t c·∫£ t√†i li·ªáu.\")\n",
    "\n",
    "    summary_prompt = f\"{SYSTEM_PERSONA_PROMPT}\\n**NHI·ªÜM V·ª§:** D·ª±a v√†o c√°c ƒëo·∫°n vƒÉn b·∫£n sau, t√≥m t·∫Øt c√°c ki·∫øn th·ª©c c·ªët l√µi nh·∫•t v·ªÅ ch·ªß ƒë·ªÅ \\\"{state.get('analyzed_objective', {}).get('topic', '')}\\\".\\n**QUY T·∫ÆC:** T√≥m t·∫Øt ph·∫£i c√¥ ƒë·ªçng, m·∫°ch l·∫°c, t·∫≠p trung v√†o ƒë·ªãnh nghƒ©a v√† ƒë·ªãnh l√Ω ch√≠nh.\\n**C√ÅC ƒêO·∫†N VƒÇN B·∫¢N:**\\n{best_snippets_text}\"\n",
    "    summary = \"Ch∆∞a c√≥ t√≥m t·∫Øt.\"\n",
    "    try:\n",
    "        summary_response = await llm.ainvoke(summary_prompt)\n",
    "        summary = summary_response.content\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i b∆∞·ªõc t√≥m t·∫Øt: {e}.\")\n",
    "        \n",
    "    resource = {\"source\": \"S√°ch gi√°o khoa (t·ª´ RAG - ƒë√£ s√†ng l·ªçc)\", \"summary\": summary}\n",
    "    print_result(resource, \"T√†i li·ªáu RAG cu·ªëi c√πng\")\n",
    "    return update_agent_outputs(state, \"resources\", resource)\n",
    "\n",
    "async def plan_delegator_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Plan Delegator` ƒëang l·∫≠p k·∫ø ho·∫°ch chi ti·∫øt...\")\n",
    "    critic_feedback_prompt = f\"**PH·∫¢N H·ªíI T·ª™ L·∫¶N TR∆Ø·ªöC (C·∫¶N S·ª¨A):** \\\"{state.get('reflection_notes', '')}\\\".\"\n",
    "    prompt = f\"\"\"{SYSTEM_PERSONA_PROMPT}\n",
    "    **NHI·ªÜM V·ª§:** X√¢y d·ª±ng m·ªôt k·∫ø ho·∫°ch b√†i d·∫°y chi ti·∫øt (danh s√°ch c√°c nhi·ªám v·ª•).\n",
    "    **M·ª§C TI√äU B√ÄI H·ªåC:** {state.get('analyzed_objective')}\n",
    "    **KI·∫æN TH·ª®C N·ªÄN T·∫¢NG:** {state.get('agent_outputs', {}).get('resources', [{}])[0].get('summary', 'Ch∆∞a c√≥ t√≥m t·∫Øt.')}\n",
    "    {critic_feedback_prompt}\n",
    "    **QUY T·∫ÆC:**\n",
    "    1.  **C·∫•u tr√∫c Logic:** B·∫Øt ƒë·∫ßu b·∫±ng gi·ªõi thi·ªáu, ti·∫øp theo l√† h√¨nh th√†nh ki·∫øn th·ª©c, sau ƒë√≥ l√† luy·ªán t·∫≠p, v√† cu·ªëi c√πng l√† ƒë√°nh gi√°/t·ªïng k·∫øt.\n",
    "    2.  **Th·ªùi gian Chu to√†n:** Ph√¢n b·ªï th·ªùi gian cho c√°c nhi·ªám v·ª• sao cho t·ªïng th·ªùi gian g·∫ßn b·∫±ng {state.get('analyzed_objective', {}).get('constraints', {}).get('duration_minutes', 90)} ph√∫t.\n",
    "    **Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:** Tr·∫£ v·ªÅ JSON v·ªõi key `tasks`, m·ªói task c√≥ `task_name`, `task_description`, `estimated_duration`.\n",
    "    \"\"\"\n",
    "    structured_llm = llm.with_structured_output(TaskListWithDuration, method=\"json_mode\")\n",
    "    try:\n",
    "        task_list_result = await structured_llm.ainvoke(prompt)\n",
    "        tasks_with_status = [{\"task_id\": i, **t.dict(), \"status\": \"pending\"} for i, t in enumerate(task_list_result.tasks) if t]\n",
    "        print_result(tasks_with_status, f\"ƒê√£ t·∫°o {len(tasks_with_status)} nhi·ªám v·ª• chi ti·∫øt\")\n",
    "        new_agent_outputs = {\"resources\": state.get(\"agent_outputs\", {}).get(\"resources\", [])}\n",
    "        return {\"task_list\": tasks_with_status, \"reflection_notes\": None, \"agent_outputs\": new_agent_outputs}\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Plan Delegator: {e}. T·∫°o task m·∫∑c ƒë·ªãnh.\")\n",
    "        return {\"task_list\": [{\"task_id\": 0, \"task_name\": \"Ho·∫°t ƒë·ªông luy·ªán t·∫≠p\", \"task_description\": \"H·ªçc sinh th·ª±c h√†nh b√†i t·∫≠p v·ªÅ ƒë∆∞·ªùng tr√≤n ngo·∫°i ti·∫øp.\", \"estimated_duration\": 45, \"status\": \"pending\"}], \"reflection_notes\": None, \"agent_outputs\": state.get(\"agent_outputs\", {})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eed0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 5: AGENTS - GIAI ƒêO·∫†N TH·ª∞C THI\n",
    "# ==============================================================================\n",
    "\n",
    "async def theory_synthesizer_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Theory Synthesizer` ƒëang so·∫°n n·ªôi dung l√Ω thuy·∫øt...\")\n",
    "    task_to_run = next((t for t in state.get('task_list', []) if t['task_id'] == state.get('current_task_id')), None)\n",
    "    if not task_to_run: return {\"current_content_to_validate\": {\"error\": \"Kh√¥ng t√¨m th·∫•y task.\"}}\n",
    "    \n",
    "    prompt = f\"\"\"{SYSTEM_PERSONA_PROMPT}\n",
    "    **NHI·ªÜM V·ª§:** T·∫°o n·ªôi dung chi ti·∫øt cho M·ªòT ho·∫°t ƒë·ªông gi·∫£ng gi·∫£i l√Ω thuy·∫øt.\n",
    "    **M√î T·∫¢ Y√äU C·∫¶U:** \"{task_to_run.get('task_description')}\"\n",
    "    **CH·ª¶ ƒê·ªÄ:** {state.get('analyzed_objective', {}).get('topic')}\n",
    "    **Y√äU C·∫¶U:** N·ªôi dung ph·∫£i c·ª• th·ªÉ, c√≥ th·ªÉ l√† c√°c g·∫°ch ƒë·∫ßu d√≤ng ki·∫øn th·ª©c ch√≠nh ho·∫∑c c√°c c√¢u h·ªèi g·ª£i m·ªü.\n",
    "    **Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:** Tr·∫£ v·ªÅ JSON theo schema `LearningActivity`.\n",
    "    \"\"\"\n",
    "    structured_llm = llm.with_structured_output(LearningActivity, method=\"json_mode\")\n",
    "    try:\n",
    "        activity_result = await structured_llm.ainvoke(prompt)\n",
    "        activity_result.duration_minutes = task_to_run.get('estimated_duration', 10)\n",
    "        print_result(activity_result.dict(), \"Ho·∫°t ƒë·ªông l√Ω thuy·∫øt ƒë√£ thi·∫øt k·∫ø\")\n",
    "        return {\"current_content_to_validate\": activity_result.dict()}\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Theory Synthesizer: {e}. Tr·∫£ v·ªÅ n·ªôi dung m·∫∑c ƒë·ªãnh.\")\n",
    "        return {\"current_content_to_validate\": {\"error\": str(e)}}\n",
    "\n",
    "async def activity_designer_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Activity Designer` ƒëang thi·∫øt k·∫ø ho·∫°t ƒë·ªông v·∫≠n d·ª•ng...\")\n",
    "    task_to_run = next((t for t in state.get('task_list', []) if t['task_id'] == state.get('current_task_id')), None)\n",
    "    if not task_to_run: return {\"current_content_to_validate\": {\"error\": \"Kh√¥ng t√¨m th·∫•y task.\"}}\n",
    "    \n",
    "    prompt = f\"\"\"{SYSTEM_PERSONA_PROMPT}\n",
    "    **NHI·ªÜM V·ª§:** Thi·∫øt k·∫ø M·ªòT ho·∫°t ƒë·ªông v·∫≠n d·ª•ng, th·ª±c h√†nh cho h·ªçc sinh.\n",
    "    **M√î T·∫¢ Y√äU C·∫¶U:** \"{task_to_run.get('task_description')}\"\n",
    "    **CH·ª¶ ƒê·ªÄ:** {state.get('analyzed_objective', {}).get('topic')}\n",
    "    **Y√äU C·∫¶U:** Ph·∫£i t·∫°o ra c√°c b√†i t·∫≠p, c√¢u h·ªèi th·∫£o lu·∫≠n c·ª• th·ªÉ.\n",
    "    **Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:** Tr·∫£ v·ªÅ JSON theo schema `LearningActivity`.\n",
    "    \"\"\"\n",
    "    structured_llm = llm.with_structured_output(LearningActivity, method=\"json_mode\")\n",
    "    try:\n",
    "        activity_result = await structured_llm.ainvoke(prompt)\n",
    "        activity_result.duration_minutes = task_to_run.get('estimated_duration', 15)\n",
    "        print_result(activity_result.dict(), \"Ho·∫°t ƒë·ªông v·∫≠n d·ª•ng ƒë√£ thi·∫øt k·∫ø\")\n",
    "        return {\"current_content_to_validate\": activity_result.dict()}\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Activity Designer: {e}. Tr·∫£ v·ªÅ n·ªôi dung m·∫∑c ƒë·ªãnh.\")\n",
    "        return {\"current_content_to_validate\": {\"error\": str(e)}}\n",
    "\n",
    "async def assessment_creator_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Assessment Creator` ƒëang t·∫°o b√†i to√°n ƒë√°nh gi√°...\")\n",
    "    task_to_run = next((t for t in state.get('task_list', []) if t['task_id'] == state.get('current_task_id')), None)\n",
    "    if not task_to_run: return {\"current_content_to_validate\": {\"error\": \"Kh√¥ng t√¨m th·∫•y task.\"}}\n",
    "    \n",
    "    prompt = f\"\"\"{SYSTEM_PERSONA_PROMPT}\n",
    "    **NHI·ªÜM V·ª§:** T·∫°o M·ªòT b√†i to√°n ƒë·ªÉ ƒë√°nh gi√° h·ªçc sinh.\n",
    "    **M√î T·∫¢ Y√äU C·∫¶U:** \"{task_to_run.get('task_description')}\"\n",
    "    **CH·ª¶ ƒê·ªÄ:** {state.get('analyzed_objective', {}).get('topic')}\n",
    "    **Y√äU C·∫¶U:** B√†i to√°n ph·∫£i c√≥ ƒë·ªÅ b√†i r√µ r√†ng, ƒë√°p √°n v√† l·ªùi gi·∫£i chi ti·∫øt.\n",
    "    **Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:** Tr·∫£ v·ªÅ JSON theo schema `AssessmentItem`.\n",
    "    \"\"\"\n",
    "    structured_llm = llm.with_structured_output(AssessmentItem, method=\"json_mode\")\n",
    "    try:\n",
    "        assessment_result = await structured_llm.ainvoke(prompt)\n",
    "        print_result(assessment_result.dict(), \"C√¢u h·ªèi ƒë√°nh gi√° ƒë√£ t·∫°o\")\n",
    "        # Th√™m duration v√†o ƒë·ªÉ nh·∫•t qu√°n, d√π model kh√¥ng y√™u c·∫ßu\n",
    "        content_dict = assessment_result.dict()\n",
    "        content_dict['duration_minutes'] = task_to_run.get('estimated_duration', 10)\n",
    "        return {\"current_content_to_validate\": content_dict}\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Assessment Creator: {e}. Tr·∫£ v·ªÅ n·ªôi dung m·∫∑c ƒë·ªãnh.\")\n",
    "        return {\"current_content_to_validate\": {\"error\": str(e)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58f5451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 6: AGENTS - GIAI ƒêO·∫†N GI√ÅM S√ÅT & T·ªîNG H·ª¢P\n",
    "# ==============================================================================\n",
    "\n",
    "async def content_validator_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Contextual Critic` ƒëang ph·∫£n bi·ªán n·ªôi dung...\")\n",
    "    content = state.get('current_content_to_validate')\n",
    "    if not content or content.get(\"error\"):\n",
    "        print_warning(\"B·ªè qua ph·∫£n bi·ªán do l·ªói ·ªü b∆∞·ªõc t·∫°o n·ªôi dung.\")\n",
    "        return {\"validation_feedback\": \"L·ªói t·∫°o n·ªôi dung, kh√¥ng th·ªÉ ph·∫£n bi·ªán.\"}\n",
    "    \n",
    "    prompt = f\"\"\"B·∫†N L√Ä M·ªòT GI√ÅO VI√äN L·ªöP {state.get('analyzed_objective', {}).get('grade_level', '9')} C·ª∞C K·ª≤ KINH NGHI·ªÜM V√Ä C·∫®N TH·∫¨N, V·ªöI CHUY√äN M√îN S√ÇU V·ªÄ **{state.get('domain', 'To√°n h·ªçc')}**.\n",
    "    **B·ªêI C·∫¢NH:** Bu·ªïi h·ªçc h√¥m nay c√≥ ch·ªß ƒë·ªÅ ch√≠nh l√† **\"{state.get('analyzed_objective', {}).get('topic', '')}\"**.\n",
    "    **NHI·ªÜM V·ª§:** H√£y xem x√©t n·ªôi dung ƒë∆∞·ª£c t·∫°o ra cho m·ªôt ho·∫°t ƒë·ªông trong gi√°o √°n.\n",
    "    **N·ªòI DUNG C·∫¶N XEM X√âT:**\n",
    "    ```json\n",
    "    {json.dumps(content, ensure_ascii=False, indent=2)}\n",
    "    ```\n",
    "    **TI√äU CH√ç PH·∫¢N BI·ªÜN:**\n",
    "    1.  **T√≠nh li√™n quan:** N·ªôi dung c√≥ li√™n quan tr·ª±c ti·∫øp ƒë·∫øn ch·ªß ƒë·ªÅ ch√≠nh c·ªßa b√†i h·ªçc kh√¥ng?\n",
    "    2.  **T√≠nh ch√≠nh x√°c chuy√™n m√¥n:** N·ªôi dung c√≥ sai s√≥t n√†o v·ªÅ ki·∫øn th·ª©c, c√¥ng th·ª©c, logic kh√¥ng?\n",
    "    **Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:** Tr·∫£ v·ªÅ JSON v·ªõi 2 key `is_valid` (boolean) v√† `feedback` (string).\n",
    "    \"\"\"\n",
    "    structured_llm = llm.with_structured_output(ValidationResult, method=\"json_mode\")\n",
    "    try:\n",
    "        result = await structured_llm.ainvoke(prompt)\n",
    "        if not result.is_valid:\n",
    "            print_warning(f\"PH·∫¢N BI·ªÜN: {result.feedback}\")\n",
    "            return {\"validation_feedback\": result.feedback}\n",
    "        else:\n",
    "            print_step(\"‚úîÔ∏è CHUY√äN GIA PH·∫¢N BI·ªÜN: N·ªôi dung h·ª£p l·ªá!\")\n",
    "            return {\"validation_feedback\": None}\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Content Validator: {e}. M·∫∑c ƒë·ªãnh cho qua.\")\n",
    "        return {\"validation_feedback\": None}\n",
    "\n",
    "def commit_validated_content_node(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Commiter`: ƒêang ghi nh·∫≠n n·ªôi dung ƒë√£ ƒë∆∞·ª£c x√°c th·ª±c...\")\n",
    "    agent_ran = state.get(\"next_agent\")\n",
    "    content = state.get(\"current_content_to_validate\")\n",
    "    current_task_id = state.get(\"current_task_id\")\n",
    "    \n",
    "    if content and agent_ran and current_task_id is not None:\n",
    "        content['task_id'] = current_task_id\n",
    "        key_to_update = \"assessments\" if agent_ran == \"assessment_creator\" else \"activities\"\n",
    "        updated_outputs = update_agent_outputs(state, key_to_update, content)\n",
    "        updated_outputs[\"current_content_to_validate\"] = None\n",
    "        return updated_outputs\n",
    "    return {}\n",
    "\n",
    "async def plan_compiler_and_critic_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Plan Compiler & Critic` ƒëang t·ªïng h·ª£p v√† ƒë√°nh gi√°...\")\n",
    "    outputs = state.get('agent_outputs', {})\n",
    "    objective = state.get('analyzed_objective', {})\n",
    "    activities = outputs.get('activities', [])\n",
    "    assessments = outputs.get('assessments', [])\n",
    "    all_content_items = activities + assessments\n",
    "    total_duration = sum(item.get('duration_minutes', 0) for item in all_content_items)\n",
    "    allowed_duration = objective.get('constraints', {}).get('duration_minutes', 90)\n",
    "    is_duration_valid = (allowed_duration * 0.85) <= total_duration <= (allowed_duration + 10)\n",
    "\n",
    "    if not all_content_items or len(all_content_items) < 3 or not is_duration_valid:\n",
    "        reflection = f\"K·∫ø ho·∫°ch th·∫•t b·∫°i. T·ªïng th·ªùi gian th·ª±c t·∫ø ({total_duration} ph√∫t) n·∫±m ngo√†i kho·∫£ng cho ph√©p. Ho·∫∑c s·ªë l∆∞·ª£ng ho·∫°t ƒë·ªông ({len(all_content_items)}) qu√° √≠t. H√£y l·∫≠p k·∫ø ho·∫°ch l·∫°i.\"\n",
    "        print_warning(f\"CRITIC: {reflection}\")\n",
    "        return {\"reflection_notes\": reflection, \"final_lesson_plan\": None}\n",
    "\n",
    "    print_step(\"CRITIC: K·∫ø ho·∫°ch h·ª£p l·ªá! B·∫Øt ƒë·∫ßu t·ªïng h·ª£p gi√°o √°n chi ti·∫øt...\")\n",
    "    all_content_sorted = sorted(all_content_items, key=lambda x: x.get('task_id', float('inf')))\n",
    "    content_md_parts = []\n",
    "    \n",
    "    for i, content in enumerate(all_content_sorted):\n",
    "        title = f\"### Ho·∫°t ƒë·ªông {i+1}: {content.get('activity_name', 'N/A')} ({content.get('duration_minutes', 0)} ph√∫t)\"\n",
    "        if 'question' in content:\n",
    "            details = (f\"*   **Lo·∫°i h√¨nh:** {content.get('question_type', 'ƒê√°nh gi√°')}\\n\"\n",
    "                       f\"*   **ƒê·ªÅ b√†i:**\\n{content.get('question', 'N/A')}\\n\\n\"\n",
    "                       f\"*   **ƒê√°p √°n:** {content.get('answer', 'N/A')}\\n\"\n",
    "                       f\"*   **H∆∞·ªõng d·∫´n gi·∫£i chi ti·∫øt:**\\n{format_solution_guide(content.get('solution_guide'))}\\n\")\n",
    "        else:\n",
    "            details = (f\"*   **Lo·∫°i h√¨nh:** {content.get('activity_type', 'N/A')}\\n\"\n",
    "                       f\"*   **M√¥ t·∫£/Nhi·ªám v·ª•:**\\n{content.get('description', 'N/A')}\\n\\n\"\n",
    "                       f\"*   **G·ª£i √Ω ƒë√°p √°n/H∆∞·ªõng d·∫´n gi·∫£i:**\\n{format_solution_guide(content.get('solution_guide'))}\\n\")\n",
    "        content_md_parts.append(f\"{title}\\n\\n{details}\")\n",
    "    \n",
    "    content_md = \"\\n---\\n\\n\".join(content_md_parts)\n",
    "    final_plan_str = f\"\"\"# GI√ÅO √ÅN B√ÄI D·∫†Y: {objective.get('topic', 'N/A')}\n",
    "---\n",
    "## I. TH√îNG TIN CHUNG\n",
    "- **M√¥n h·ªçc:** {state.get('domain', 'N/A')}\n",
    "- **L·ªõp:** {objective.get('grade_level', 'N/A')}\n",
    "- **Th·ªùi l∆∞·ª£ng d·ª± ki·∫øn:** {total_duration} ph√∫t / {allowed_duration} ph√∫t\n",
    "- **Ph∆∞∆°ng ph√°p s∆∞ ph·∫°m ch·ªß ƒë·∫°o:** {state.get('pedagogy_strategy', {}).get('chosen_pedagogy', 'Ch∆∞a x√°c ƒë·ªãnh')}\n",
    "---\n",
    "## II. M·ª§C TI√äU B√ÄI H·ªåC\n",
    "- H·ªçc sinh c√≥ th·ªÉ **{objective.get('action_verb', 'v·∫≠n d·ª•ng')}** ki·∫øn th·ª©c v·ªÅ {objective.get('topic', 'N/A')} ƒë·ªÉ gi·∫£i quy·∫øt c√°c b√†i to√°n li√™n quan.\n",
    "---\n",
    "## III. CHU·∫®N B·ªä\n",
    "- **Gi√°o vi√™n:** B·∫£ng ph·ª•, ph·∫•n m√†u, phi·∫øu h·ªçc t·∫≠p.\n",
    "- **H·ªçc sinh:** S√°ch gi√°o khoa, v·ªü ghi, d·ª•ng c·ª• h·ªçc t·∫≠p.\n",
    "- **Ngu·ªìn t√†i li·ªáu tham kh·∫£o:** {state.get('agent_outputs', {}).get('resources', [{}])[0].get('source', 'N/A')}\n",
    "---\n",
    "## IV. TI·∫æN TR√åNH B√ÄI D·∫†Y\n",
    "{content_md}\n",
    "---\n",
    "## V. T√ìM T·∫ÆT KI·∫æN TH·ª®C C·ªêT L√ïI\n",
    "{state.get('agent_outputs', {}).get('resources', [{}])[0].get('summary', 'Ch∆∞a c√≥ t√≥m t·∫Øt.')}\n",
    "\"\"\"\n",
    "    return {\"final_lesson_plan\": final_plan_str, \"reflection_notes\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f9faa90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initialize_state_node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     61\u001b[39m workflow = StateGraph(TeacherStateV4)\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Giai ƒëo·∫°n 1: Ph√¢n t√≠ch & L·∫≠p chi·∫øn l∆∞·ª£c\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33minitializer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43minitialize_state_node\u001b[49m)\n\u001b[32m     65\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33mobjective_interpreter\u001b[39m\u001b[33m\"\u001b[39m, objective_interpreter_agent)\n\u001b[32m     66\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33mpedagogy_strategist\u001b[39m\u001b[33m\"\u001b[39m, pedagogy_strategist_agent)\n",
      "\u001b[31mNameError\u001b[39m: name 'initialize_state_node' is not defined"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELL 7: L·∫ÆP R√ÅP GRAPH & CH·∫†Y TH·ª¨ NGHI·ªÜM\n",
    "# ==============================================================================\n",
    "\n",
    "# --- C√ÅC NODE TI·ªÜN √çCH V√Ä ƒêI·ªÄU PH·ªêI ---\n",
    "def mark_task_complete(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    task_list = state.get(\"task_list\", [])\n",
    "    current_task_id = state.get(\"current_task_id\")\n",
    "    if not task_list or current_task_id is None: return {}\n",
    "    new_task_list = [t.copy() for t in task_list]\n",
    "    for task in new_task_list:\n",
    "        if task.get(\"task_id\") == current_task_id:\n",
    "            task[\"status\"] = \"completed\"\n",
    "            break\n",
    "    return {\"task_list\": new_task_list, \"current_task_id\": None}\n",
    "    \n",
    "def task_router_node(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Router`: ƒêang ki·ªÉm tra nhi·ªám v·ª•...\")\n",
    "    task_list = state.get(\"task_list\", [])\n",
    "    next_task = next((task for task in task_list if task.get(\"status\") == \"pending\"), None)\n",
    "    if next_task:\n",
    "        print_step(f\"Nhi·ªám v·ª• ti·∫øp theo: '{next_task['task_name']}' (ID: {next_task['task_id']})\")\n",
    "        return {\"current_task_id\": next_task['task_id']}\n",
    "    else:\n",
    "        print_step(\"H·∫øt nhi·ªám v·ª•, chuy·ªÉn sang node Compiler & Critic.\")\n",
    "        return {\"current_task_id\": None}\n",
    "\n",
    "async def task_dispatcher_agent(state: \"TeacherStateV4\") -> Dict[str, Any]:\n",
    "    print_step(\"`Agent: Task Dispatcher` B·∫Øt ƒë·∫ßu...\")\n",
    "    task_to_run = next((t for t in state.get('task_list', []) if t['task_id'] == state.get('current_task_id')), None)\n",
    "    if not task_to_run:\n",
    "        print_warning(\"Dispatcher kh√¥ng t√¨m th·∫•y task, s·∫Ω b·ªè qua b∆∞·ªõc n√†y.\")\n",
    "        return {\"next_agent\": \"mark_task_complete\"}\n",
    "\n",
    "    task_description = task_to_run.get('task_description', '')\n",
    "    prompt = f\"{SYSTEM_PERSONA_PROMPT}\\n**Nhi·ªám v·ª•:** Ph√¢n lo·∫°i nhi·ªám v·ª• sau v√†o M·ªòT trong ba agent sau: 'activity_designer', 'theory_synthesizer', 'assessment_creator'.\\n\\n**QUY T·∫ÆC PH√ÇN LO·∫†I:**\\n- Gi·∫£ng gi·∫£i, gi·ªõi thi·ªáu, √¥n t·∫≠p, t·ªïng k·∫øt -> 'theory_synthesizer'.\\n- Luy·ªán t·∫≠p, th·ª±c h√†nh, th·∫£o lu·∫≠n -> 'activity_designer'.\\n- Ki·ªÉm tra, ƒë√°nh gi√°, v·∫≠n d·ª•ng cao -> 'assessment_creator'.\\n\\n**NHI·ªÜM V·ª§ C·∫¶N PH√ÇN LO·∫†I:** \\\"{task_description}\\\"\\n\\n**Y√äU C·∫¶U JSON:** Tr·∫£ v·ªÅ JSON v·ªõi key duy nh·∫•t l√† `agent_category`.\"\n",
    "    structured_llm = llm.with_structured_output(TaskClassification)\n",
    "    try:\n",
    "        classification_result = await structured_llm.ainvoke(prompt)\n",
    "        next_agent = classification_result.agent_category\n",
    "    except Exception as e:\n",
    "        print_warning(f\"L·ªói t·∫°i Dispatcher: {e}. Giao nhi·ªám v·ª• cho 'activity_designer'.\")\n",
    "        next_agent = \"activity_designer\"\n",
    "    print_step(f\"--- üöö `Dispatcher`: Giao nhi·ªám v·ª• cho `{next_agent}`.\")\n",
    "    return {\"next_agent\": next_agent}\n",
    "\n",
    "# --- C√ÅC H√ÄM ƒêI·ªÄU H∆Ø·ªöNG ---\n",
    "def route_after_validation(state: \"TeacherStateV4\") -> Literal[\"commit\", \"retry\"]:\n",
    "    if state.get(\"validation_feedback\") is None: return \"commit\"\n",
    "    else: return \"retry\"\n",
    "\n",
    "def route_after_router(state: \"TeacherStateV4\") -> Literal[\"continue_executing\", \"compile_and_critique\"]:\n",
    "    if state.get(\"current_task_id\") is None: return \"compile_and_critique\"\n",
    "    else: return \"continue_executing\"\n",
    "\n",
    "def route_after_compilation(state: \"TeacherStateV4\") -> Literal[\"finish\", \"replan\"]:\n",
    "    if state.get(\"reflection_notes\"): return \"replan\"\n",
    "    else: return \"finish\"\n",
    "\n",
    "# --- X√ÇY D·ª∞NG GRAPH ---\n",
    "workflow = StateGraph(TeacherStateV4)\n",
    "\n",
    "# Giai ƒëo·∫°n 1: Ph√¢n t√≠ch & L·∫≠p chi·∫øn l∆∞·ª£c\n",
    "workflow.add_node(\"initializer\", initialize_state_node)\n",
    "workflow.add_node(\"objective_interpreter\", objective_interpreter_agent)\n",
    "workflow.add_node(\"pedagogy_strategist\", pedagogy_strategist_agent)\n",
    "\n",
    "# Giai ƒëo·∫°n 2: Thu th·∫≠p & L·∫≠p k·∫ø ho·∫°ch\n",
    "workflow.add_node(\"query_expansion\", query_expansion_agent)\n",
    "workflow.add_node(\"resource_scout\", resource_scout_agent_v2)\n",
    "workflow.add_node(\"plan_delegator\", plan_delegator_agent)\n",
    "\n",
    "# Giai ƒëo·∫°n 3: V√≤ng l·∫∑p Th·ª±c thi & Ki·ªÉm duy·ªát\n",
    "workflow.add_node(\"task_router\", task_router_node)\n",
    "workflow.add_node(\"task_dispatcher\", task_dispatcher_agent)\n",
    "workflow.add_node(\"theory_synthesizer\", theory_synthesizer_agent)\n",
    "workflow.add_node(\"activity_designer\", activity_designer_agent)\n",
    "workflow.add_node(\"assessment_creator\", assessment_creator_agent)\n",
    "workflow.add_node(\"content_validator\", content_validator_agent)\n",
    "workflow.add_node(\"commit_validated_content\", commit_validated_content_node)\n",
    "workflow.add_node(\"mark_task_complete\", mark_task_complete)\n",
    "\n",
    "# Giai ƒëo·∫°n 4: T·ªïng h·ª£p & Ph√™ b√¨nh\n",
    "workflow.add_node(\"plan_compiler_and_critic\", plan_compiler_and_critic_agent)\n",
    "\n",
    "# K·∫øt n·ªëi d√¢y chuy·ªÅn\n",
    "workflow.set_entry_point(\"initializer\")\n",
    "workflow.add_edge(\"initializer\", \"objective_interpreter\")\n",
    "workflow.add_edge(\"objective_interpreter\", \"pedagogy_strategist\")\n",
    "workflow.add_edge(\"pedagogy_strategist\", \"query_expansion\")\n",
    "workflow.add_edge(\"query_expansion\", \"resource_scout\")\n",
    "workflow.add_edge(\"resource_scout\", \"plan_delegator\")\n",
    "workflow.add_edge(\"plan_delegator\", \"task_router\")\n",
    "\n",
    "# V√≤ng l·∫∑p ch√≠nh\n",
    "workflow.add_conditional_edges(\"task_router\", route_after_router, {\"continue_executing\": \"task_dispatcher\", \"compile_and_critique\": \"plan_compiler_and_critic\"})\n",
    "workflow.add_conditional_edges(\"task_dispatcher\", lambda state: state.get(\"next_agent\", \"activity_designer\"), {\"activity_designer\": \"activity_designer\", \"assessment_creator\": \"assessment_creator\", \"theory_synthesizer\": \"theory_synthesizer\"})\n",
    "\n",
    "# V√≤ng l·∫∑p ki·ªÉm duy·ªát vi m√¥\n",
    "workflow.add_edge(\"theory_synthesizer\", \"content_validator\")\n",
    "workflow.add_edge(\"activity_designer\", \"content_validator\")\n",
    "workflow.add_edge(\"assessment_creator\", \"content_validator\")\n",
    "workflow.add_conditional_edges(\"content_validator\", route_after_validation, {\"commit\": \"commit_validated_content\", \"retry\": \"task_dispatcher\"})\n",
    "workflow.add_edge(\"commit_validated_content\", \"mark_task_complete\")\n",
    "workflow.add_edge(\"mark_task_complete\", \"task_router\")\n",
    "\n",
    "# V√≤ng l·∫∑p ph√™ b√¨nh vƒ© m√¥\n",
    "workflow.add_conditional_edges(\"plan_compiler_and_critic\", route_after_compilation, {\"replan\": \"plan_delegator\", \"finish\": END})\n",
    "\n",
    "app = workflow.compile()\n",
    "print(\"‚úÖ Graph phi√™n b·∫£n 'B√°o c√°o' ƒë√£ ƒë∆∞·ª£c bi√™n d·ªãch th√†nh c√¥ng.\")\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói v·∫Ω bi·ªÉu ƒë·ªì: {e}\")\n",
    "\n",
    "# --- CH·∫†Y TH·ª¨ NGHI·ªÜM ---\n",
    "async def run_final_version(user_request: str):\n",
    "    if 'llm' not in globals() or llm is None or 'vector_store' not in globals() or vector_store is None or 'app' not in globals():\n",
    "        print_warning(\"M·ªôt trong c√°c th√†nh ph·∫ßn c·ªët l√µi (LLM, Vector Store, App) ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng ch·∫°y l·∫°i c√°c cell tr√™n.\")\n",
    "        return\n",
    "\n",
    "    initial_state = {\"messages\": [HumanMessage(content=user_request)]}\n",
    "    console.print(f\"\\n[bold magenta]üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH PHI√äN B·∫¢N 'B√ÅO C√ÅO' V·ªöI Y√äU C·∫¶U:[/bold magenta]\\n> {user_request}\")\n",
    "    config = {\"recursion_limit\": 150} \n",
    "    \n",
    "    final_state_result = None\n",
    "    try:\n",
    "        async for event in app.astream(initial_state, config=config):\n",
    "            for node_name, node_output in event.items():\n",
    "                console.print(f\"\\n[bold yellow]------- Ho√†n th√†nh b∆∞·ªõc: {node_name} -------[/bold yellow]\")\n",
    "                final_state_result = node_output\n",
    "\n",
    "        console.print(\"\\n[bold magenta]üèÅ K·∫æT TH√öC QUY TR√åNH.[/bold magenta]\")\n",
    "        \n",
    "        if final_state_result and final_state_result.get(\"final_lesson_plan\"):\n",
    "            console.print(\"\\n[bold green]üìù GI√ÅO √ÅN HO√ÄN CH·ªàNH[/bold green]\")\n",
    "            console.print(Markdown(final_state_result[\"final_lesson_plan\"]))\n",
    "        else:\n",
    "            print_warning(\"Kh√¥ng t·∫°o ƒë∆∞·ª£c gi√°o √°n cu·ªëi c√πng.\")\n",
    "            pprint(final_state_result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print_warning(f\"ƒê√£ x·∫£y ra l·ªói nghi√™m tr·ªçng: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "report_request = \"So·∫°n gi√∫p t√¥i gi√°o √°n b√†i 'ƒê∆∞·ªùng tr√≤n ngo·∫°i ti·∫øp v√† ƒë∆∞·ªùng tr√≤n n·ªôi ti·∫øp' cho h·ªçc sinh l·ªõp 9 trong 90 ph√∫t. ƒê√¢y l√† m·ªôt l·ªõp h·ªçc kh√° y·∫øu, c√°c em th∆∞·ªùng m·∫•t t·∫≠p trung v√† c·∫ßn c√°c ho·∫°t ƒë·ªông c√≥ t√≠nh t∆∞∆°ng t√°c cao.\"\n",
    "VERBOSE_MODE = True \n",
    "\n",
    "await run_final_version(report_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bebfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plan_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
